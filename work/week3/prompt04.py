'''
day#2
#This code is part of the LangChain Groq integration example.
# It demonstrates how to evaluate prompts using a language model, focusing on metrics like relevance, specificity, and consistency.
# It defines a `PromptEval` class that computes these metrics based on responses generated by the model.
# The `compute_specificity` method calculates the uniqueness of words in a response,
# the `compute_relevance` method measures how closely a response matches expected content,
# and the `compute_consistency` method evaluates the similarity of multiple responses to the same prompt
# The `compare_prompts` method compares multiple prompts against expected content and returns a DataFrame
# with the computed metrics for each prompt. 
'''

import numpy as np
import pandas as pd
from langchain_groq import ChatGroq
from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers import SentenceTransformer
from dotenv import load_dotenv
load_dotenv()

class PromptEval:
    def __init__(self):
        self.llm = ChatGroq(model="llama-3.1-8b-instant", temperature=1.2) 
        self.sentence_model = SentenceTransformer('all-MiniLM-L6-v2')
        
    def compute_specificity(self, response):
        words = response.split()
        unique_words = set(words)
        return len(unique_words) / len(words) if words else 0
    
    def compute_relevance(self, response, expected_content):
        embeddings = self.sentence_model.encode([response, expected_content])
        return cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]

    def compute_consistency(self, prompt, num_responses=3):
        similarities = []
        responses = [self.llm.invoke(prompt).content for _ in range(num_responses)]
        for i in range(len(responses)):
            for j in range(i+1, len(responses)):
                similarities.append(self.compute_relevance(responses[i], responses[j]))
        return np.mean(similarities)

    def compare_prompts(self, prompts, expected_content):
        results = []
        for prompt in prompts:
            response = self.llm.invoke(prompt).content
            relevance = self.compute_relevance(response, expected_content)
            specificity = self.compute_specificity(response)
            consistency = self.compute_consistency(prompt)
            results.append(
                {
                    # "response": response,
                    "relevance": relevance,
                    "specificity": specificity,
                    "consistency": consistency,
                }
            )
        results = pd.DataFrame.from_dict(results) #what is this line for?
        # This line converts the list of dictionaries into a pandas DataFrame for easier analysis and manipulation.         
        return results


if __name__ == "__main__":
    eval = PromptEval()

    joey_speech = """It's a love based on giving and receiving, as well as having and sharing. And the love that they give and have is shared and received. And through this having and giving and sharing and receiving, we too can share and love and have... and receive.
    When we share the giving and experience the receiving, we find ourselves having what was received and receiving what was shared. For in sharing what we have and having what we share, the giving becomes receiving and the receiving becomes giving.
    The beauty of their bond comes from receiving what is given and giving what is had. As they share in having and have in sharing, we witness how receiving the shared and sharing the received creates a circle of having what is given and giving what is had.
    Life together means giving to sharing and sharing in receiving. When they receive what is shared and share what is received, they discover having given and giving had. Through receiving the having and having the receiving, sharing gives and giving shares.
    Their commitment shows how having received and receiving had leads to sharing given and giving shared. As they give to having and have in giving, the sharing receives while the receiving shares. This exchange of having shared and sharing had completes the giving received and receiving given
    """

    quantum_mechanics = """ Quantum mechanics reveals a universe fundamentally different from our everyday experience. At the subatomic level, particles exhibit wave-like properties, existing in multiple states simultaneously until measured. This principle, known as superposition, challenges our classical intuition.
    Heisenberg's uncertainty principle demonstrates we cannot precisely know both position and momentum of a particle. Quantum entanglement allows particles to maintain instantaneous connections regardless of distance, what Einstein called "spooky action at a distance."
    Quantum tunneling enables particles to pass through seemingly impenetrable barriers. Wave function collapse occurs when observation forces quantum systems to resolve into definite states.
    These counterintuitive phenomena form the backbone of modern technologyâ€”from lasers to MRI machines to transistors in computing devices. While mathematically robust, quantum theory continues to spark philosophical debates about reality's true nature and the role of consciousness in the universe.
    Understanding quantum mechanics requires abandoning classical determinism for probabilistic thinking, reminding us that the cosmos operates by rules far stranger and more beautiful than we initially imagined.RetryClaude can make mistakes. Please double-check responses.
    """

    joey_specificity = eval.compute_specificity(joey_speech)
    quantum_specificity = eval.compute_specificity(quantum_mechanics)

    prompts = [
        "List the types of machine learning.",
        "What are the main categories of machine learning algorithms?",
        "Explain the different approaches to machine learning.",
        "What types of machine learning can you think about? Explain like you are Shakespear, Darwin, or Einstein. Choose any of these personality"
    ]

    expected_content = "The main types of machine learning are supervised learning, unsupervised learning, and reinforcement learning."
    compare_prompt_results = eval.compare_prompts(prompts, expected_content)
    #print(compare_prompt_results)
